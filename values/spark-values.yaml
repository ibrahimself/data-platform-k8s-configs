# Spark Operator Configuration for Data Platform
# Compatible with spark-operator chart v2.x

# Image configuration
image:
  repository: kubeflow/spark-operator
  tag: v2.1.0-release
  pullPolicy: IfNotPresent

# Webhook configuration
webhook:
  enable: true
  port: 443

# Service account configuration
serviceAccounts:
  spark:
    create: true
    name: spark
    automountServiceAccountToken: true
  sparkoperator:
    create: true
    name: spark-operator
    automountServiceAccountToken: true

# RBAC configuration
rbac:
  create: true
  createClusterRole: true
  createRole: true

# Controller configuration
controller:
  # Number of worker threads
  workers: 10
  # Resync interval
  resyncInterval: 30s
  # Queue configuration
  queueConfig:
    qps: 50
    burst: 500
    maxDelay:
      enable: true
      duration: 6h

# Resources for the operator pod
resources:
  requests:
    cpu: 100m
    memory: 300Mi
  limits:
    cpu: 200m
    memory: 500Mi

# Node selector for operator pod
nodeSelector: {}

# Pod security context
securityContext:
  runAsNonRoot: true
  runAsUser: 1000
  runAsGroup: 1000
  fsGroup: 1000

# Spark job namespaces
spark:
  jobNamespaces:
    - spark

# Metrics configuration
metrics:
  enable: true
  port: 10254
  endpoint: /metrics
  prometheus:
    enable: true
    port: 10254
    endpoint: /metrics

# Prometheus ServiceMonitor
prometheus:
  enable: true
  serviceMonitor:
    enable: true
    labels:
      prometheus: kube-prometheus-stack
    interval: 30s

# Log level
logLevel: info

# Leader election (for HA)
leaderElection:
  enable: true

# Environment variables for the operator
env: []

# Volume mounts for the operator
volumeMounts: []

# Volumes for the operator
volumes: []

# Affinity settings for the operator
affinity: {}

# Tolerations for the operator
tolerations: []

# Priority class for the operator
priorityClassName: ""

# Pod annotations
podAnnotations: {}

# Pod labels
podLabels: {}

# Enable batch scheduler integration
batchScheduler:
  enable: false

# Resource quota enforcement
resourceQuotaEnforcement:
  enable: false

# Ingress URL format
ingressUrlFormat: ""

# Time to live for completed SparkApplication objects
timeToLiveSeconds:
  enable: false
  value: 86400

# Default Spark configuration
sparkDefaults: |
  spark.eventLog.enabled=true
  spark.eventLog.dir=file:///tmp/spark-events
  spark.history.fs.logDirectory=file:///tmp/spark-events