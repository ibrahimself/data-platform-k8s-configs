# Apache Airflow configuration for Data Platform

executor: "KubernetesExecutor"

images:
  airflow:
    repository: apache/airflow
    tag: "2.10.5"

# Disable internal PostgreSQL
postgresql:
  enabled: false

# External database configuration
data:
  metadataSecretName: airflow-metadata-secret
  resultBackendSecretName: airflow-result-backend-secret

# Webserver configuration
webserver:
  replicas: 1
  defaultUser:
    enabled: false  # We already created the user
  waitForMigrations:
    enabled: false  # Database is already initialized

# Scheduler configuration  
scheduler:
  replicas: 1
  waitForMigrations:
    enabled: false  # Database is already initialized

# Disable triggerer for now
triggerer:
  enabled: false

# Disable unused components
redis:
  enabled: false
flower:
  enabled: false

# DAGs persistence
dags:
  persistence:
    enabled: true
    size: 10Gi
    storageClassName: gp2
    accessMode: ReadWriteOnce
    existingClaim: airflow-dags

# Logs persistence
logs:
  persistence:
    enabled: false

# Fernet key
fernetKeySecretName: airflow-fernet-key

# Service accounts
serviceAccount:
  create: true
  name: airflow

workers:
  serviceAccount:
    create: true
    name: airflow-worker

# RBAC
rbac:
  create: true

# Security contexts
securityContext:
  runAsUser: 50000
  runAsGroup: 0
  fsGroup: 0

# Monitoring
metrics:
  enabled: true
  serviceMonitor:
    enabled: true
    interval: 30s
    labels:
      prometheus: kube-prometheus
      release: prometheus-stack

# StatsD for metrics
statsd:
  enabled: true

# Disable ingress (we manage it separately)
ingress:
  enabled: false

# Disable migration job (already done)
migrateDatabaseJob:
  enabled: false

# Disable create user job (already done)
createUserJob:
  enabled: false

# Extra pip packages
extraPipPackages:
  - apache-airflow-providers-kubernetes>=8.0.0
  - apache-airflow-providers-postgres>=5.0.0
  - apache-airflow-providers-amazon>=8.0.0
  - apache-airflow-providers-spark>=4.0.0