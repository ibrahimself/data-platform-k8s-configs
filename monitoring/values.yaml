# monitoring/values.yaml
# Prometheus monitoring stack configuration

# Global configuration
global:
  imageRegistry: ""
  imagePullSecrets: []

# Prometheus Operator configuration
prometheusOperator:
  enabled: true
  
  # Resources
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 500m
      memory: 512Mi
  
  # Service account
  serviceAccount:
    create: true
    name: prometheus-operator
  
  # Node selection - use system nodes
  nodeSelector:
    node-group: system

# Prometheus configuration
prometheus:
  enabled: true
  
  # Service account
  serviceAccount:
    create: true
    name: prometheus
    annotations:
      # Note: This role needs to be created with proper S3 permissions if using remote write
      eks.amazonaws.com/role-arn: "arn:aws:iam::399883341639:role/data-platform-prometheus-s3-access"
  
  # Prometheus spec
  prometheusSpec:
    # Retention and storage
    retention: 30d
    retentionSize: "50GB"
    
    # Storage configuration
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: gp2
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 100Gi
    
    # Resource configuration
    resources:
      requests:
        cpu: 500m
        memory: 2Gi
      limits:
        cpu: 2000m
        memory: 4Gi
    
    # Scraping configuration
    serviceMonitorSelectorNilUsesHelmValues: false
    serviceMonitorSelector: {}
    ruleSelectorNilUsesHelmValues: false
    ruleSelector: {}
    
    # External labels
    externalLabels:
      cluster: "data-platform"
      environment: "production"
      region: "eu-west-3"
    
    # Pod monitoring
    podMonitorSelectorNilUsesHelmValues: false
    podMonitorSelector: {}
    
    # Additional scrape configs
    additionalScrapeConfigs: []
    
    # Security context
    securityContext:
      runAsUser: 65534
      runAsGroup: 65534
      runAsNonRoot: true
      fsGroup: 65534
    
    # Node selection - use system nodes
    nodeSelector:
      node-group: system
  
  # Service configuration
  service:
    type: ClusterIP
    port: 9090
    annotations: {}

# Grafana configuration
grafana:
  enabled: true
  
  # Admin credentials
  adminPassword: "changeme123!"  # IMPORTANT: Change in production
  
  # Service configuration
  service:
    type: ClusterIP
    port: 80
    annotations: {}
  
  # Resource configuration
  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 500m
      memory: 512Mi
  
  # Persistence
  persistence:
    enabled: true
    type: pvc
    storageClassName: gp2
    accessModes:
      - ReadWriteOnce
    size: 10Gi
  
  # Node selection - use system nodes
  nodeSelector:
    node-group: system
  
  # Data sources
  sidecar:
    datasources:
      enabled: true
      defaultDatasourceEnabled: true
      label: grafana_datasource
      labelValue: "1"
    
    dashboards:
      enabled: true
      label: grafana_dashboard
      labelValue: "1"
      folder: /tmp/dashboards
      folderAnnotation: grafana_folder
      provider:
        foldersFromFilesStructure: true
  
  # Grafana configuration
  grafana.ini:
    server:
      domain: grafana.data-platform.local
      root_url: "%(protocol)s://%(domain)s/"
    
    security:
      admin_user: admin
      admin_password: changeme123!  # Match the adminPassword above
    
    users:
      allow_sign_up: false
      auto_assign_org: true
      auto_assign_org_role: Viewer
    
    auth.anonymous:
      enabled: false
    
    log:
      mode: console
    
    paths:
      data: /var/lib/grafana/
      logs: /var/log/grafana
      plugins: /var/lib/grafana/plugins
      provisioning: /etc/grafana/provisioning

# AlertManager configuration
alertmanager:
  enabled: true
  
  # Service account
  serviceAccount:
    create: true
    name: alertmanager
  
  # AlertManager spec
  alertmanagerSpec:
    # Storage
    storage:
      volumeClaimTemplate:
        spec:
          storageClassName: gp2
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 10Gi
    
    # Resources
    resources:
      requests:
        cpu: 100m
        memory: 128Mi
      limits:
        cpu: 500m
        memory: 256Mi
    
    # Retention
    retention: 720h
    
    # Security context
    securityContext:
      runAsUser: 65534
      runAsGroup: 65534
      runAsNonRoot: true
      fsGroup: 65534
    
    # Node selection - use system nodes
    nodeSelector:
      node-group: system
  
  # Service configuration
  service:
    type: ClusterIP
    port: 9093

  # AlertManager configuration
  config:
    global:
      smtp_smarthost: 'localhost:587'
      smtp_from: 'alerts@data-platform.local'
    
    route:
      group_by: ['alertname', 'cluster', 'service']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 1h
      receiver: 'default-receiver'
      routes:
      - match:
          severity: critical
        receiver: 'critical-receiver'
        continue: true
    
    receivers:
    - name: 'default-receiver'
      # Configure your notification channels here
      
    - name: 'critical-receiver'
      # Configure critical alerts here
      # slack_configs:
      # - api_url: 'YOUR_SLACK_WEBHOOK_URL'
      #   channel: '#critical-alerts'
      #   title: 'Critical Alert - Data Platform'
      #   text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'

# Node Exporter
nodeExporter:
  enabled: true
  
  # Service account
  serviceAccount:
    create: true
    name: node-exporter
  
  # Resources
  resources:
    requests:
      cpu: 50m
      memory: 64Mi
    limits:
      cpu: 200m
      memory: 128Mi

# kube-state-metrics
kubeStateMetrics:
  enabled: true
  
  # Resources
  resources:
    requests:
      cpu: 10m
      memory: 32Mi
    limits:
      cpu: 100m
      memory: 64Mi
  
  # Node selection - use system nodes
  nodeSelector:
    node-group: system

# CoreDNS monitoring
coreDns:
  enabled: true

# kube-apiserver monitoring
kubeApiServer:
  enabled: true

# kube-controller-manager monitoring
kubeControllerManager:
  enabled: true

# etcd monitoring
kubeEtcd:
  enabled: true

# kube-scheduler monitoring
kubeScheduler:
  enabled: true

# kubelet monitoring
kubelet:
  enabled: true
  
  # ServiceMonitor configuration
  serviceMonitor:
    cAdvisorMetricRelabelings:
      # Drop high-cardinality metrics
      - sourceLabels: [__name__]
        regex: 'container_network_tcp_usage_total'
        action: drop
      - sourceLabels: [__name__]
        regex: 'container_tasks_state'
        action: drop

# Default rules (alerts)
defaultRules:
  create: true
  rules:
    alertmanager: true
    etcd: true
    general: true
    k8s: true
    kubeApiserver: true
    kubeApiserverAvailability: true
    kubeApiserverSlos: true
    kubelet: true
    kubePrometheusGeneral: true
    kubePrometheusNodeRecording: true
    kubernetesApps: true
    kubernetesResources: true
    kubernetesStorage: true
    kubernetesSystem: true
    node: true
    prometheus: true
    prometheusOperator: true

# Additional ServiceMonitors for custom applications
additionalServiceMonitors:
  - name: dremio-monitoring
    labels:
      app: dremio
    selector:
      matchLabels:
        app: dremio
    endpoints:
    - port: metrics
      path: /metrics
      interval: 30s
  
  - name: spark-monitoring
    labels:
      app: spark-operator
    selector:
      matchLabels:
        app.kubernetes.io/name: spark-operator
    endpoints:
    - port: metrics
      path: /metrics
      interval: 30s
  
  - name: airflow-monitoring
    labels:
      app: airflow
    selector:
      matchLabels:
        component: webserver
        release: airflow
    endpoints:
    - port: statsd-exporter
      path: /metrics
      interval: 30s

# Additional PrometheusRules for custom alerts
additionalPrometheusRules:
  - name: data-platform-alerts
    groups:
    - name: dremio.rules
      rules:
      - alert: DremioDown
        expr: up{job="dremio"} == 0
        for: 5m
        labels:
          severity: critical
          service: dremio
        annotations:
          summary: "Dremio instance is down"
          description: "Dremio has been down for more than 5 minutes in {{ $labels.namespace }}."
    
    - name: spark.rules
      rules:
      - alert: SparkOperatorDown
        expr: up{job="spark-operator"} == 0
        for: 5m
        labels:
          severity: warning
          service: spark
        annotations:
          summary: "Spark Operator is down"
          description: "Spark Operator has been down for more than 5 minutes."
    
    - name: airflow.rules
      rules:
      - alert: AirflowSchedulerDown
        expr: up{job="airflow-scheduler"} == 0
        for: 5m
        labels:
          severity: critical
          service: airflow
        annotations:
          summary: "Airflow Scheduler is down"
          description: "Airflow Scheduler has been down for more than 5 minutes."