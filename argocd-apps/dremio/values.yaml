# argocd-apps/dremio/values.yaml
# Dremio Enterprise Edition configuration

dremio:
  # Your trial license (valid until 2025-06-18)
  license: "eyJraWQiOiI4MGZhMjgxYzZhZjczNDNkNTE1YTVhMzg1MDg1N2RhNmE2YmEzMTU3NWE5ZjVlZmVhMmQ4MTkyMGUyM2Q2OGY0IiwiYWxnIjoiRVMyNTYifQ.eyJpc3MiOiJEcmVtaW8iLCJzdWIiOiIwMDM1ZDAwMDA3TFRkT0VBQTEiLCJuYmYiOjE3NTI3ODA0NzYsImV4cCI6MTc1NTU0NTI3NiwiaWF0IjoxNzUyNzgwNDc2LCJqdGkiOiIxNzUyNzgwNDc2MDYyVzJjciJ9.u8bxfpQvyieeGn3H8RNIyKqbIgHR4pYO0mfBDBh23WJJw58t2WsDEhbOL6rUdfyGu4hItUtcohCoSEXMaAAolg"
  
  image:
    repository: quay.io/dremio/dremio-enterprise
    tag: "26.0.1" 
    pullPolicy: IfNotPresent

  # Performance and configuration optimizations
  dremioConfExtraOptions:
    # Performance settings
    "services.coordinator.web.port": "9047"
    "services.coordinator.web.ssl.enabled": "false"
    "services.fabric.memory.reservation": "4G"
    "services.coordinator.heap.memory.max": "8G"
    "services.executor.heap.memory.max": "8G"
    "services.coordinator.enable-heap-monitoring": "true"
    
    # If using S3, uncomment and configure:
    # "paths.dist": "s3a://your-bucket-name/dremio"

# Image pull secrets - use the secret we created
imagePullSecrets:
  - dremio-trial-pull-secret

# Coordinator (Master) configuration
coordinator:
  count: 1
  
  # Web interface configuration
  web:
    auth:
      enabled: true
      type: "internal"  # Can be: internal, ldap, azuread, oauth, oauth+ldap
    port: 9047
    ssl:
      enabled: false

  # Resource allocation
  resources:
    requests:
      cpu: "2"
      memory: "8Gi"
    limits:
      cpu: "4"
      memory: "16Gi"

  # Service configuration for external access
  service:
    type: ClusterIP
    port: 9047

  # Persistent storage for coordinator metadata
  volumeClaimTemplate:
    storageClassName: "gp2"  # Update based on your storage class
    accessModes: ["ReadWriteOnce"]
    resources:
      requests:
        storage: 100Gi

  # Node selection - use analytics nodes if available
  nodeSelector: {}
    # node-group: analytics  # Uncomment if you have node groups

# Executor configuration
executor:
  count: 3
  
  # Resource allocation for executors
  resources:
    requests:
      cpu: "2"
      memory: "8Gi"
    limits:
      cpu: "4"
      memory: "16Gi"

  # Executor storage for caching and spill
  volumeClaimTemplate:
    storageClassName: "gp2"  # Update based on your storage class
    accessModes: ["ReadWriteOnce"]
    resources:
      requests:
        storage: 100Gi

  # Node selection for executors
  nodeSelector: {}
    # node-group: compute  # Uncomment if you have node groups
  
  # Spread executors across nodes
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
            - key: app
              operator: In
              values:
              - dremio-executor
          topologyKey: kubernetes.io/hostname

# Distributed storage configuration
# Choose one of: aws, gcp, or azureStorage
distStorage:
  # For local development/testing, you can use PVCs
  # For production, configure S3, GCS, or Azure Storage
  
  # Option 1: AWS S3 (most common)
  type: "aws"
  aws:
    bucketName: "your-s3-bucket-name"  # CHANGE THIS
    path: "/dremio"
    authentication: "metadata"  # Use IAM roles (recommended for EKS)
    # For access key authentication, use:
    # authentication: "accessKeySecret"
    # credentials:
    #   accessKey: "YOUR_ACCESS_KEY"
    #   secret: "YOUR_SECRET_KEY"
    
    # S3 performance optimizations
    extraProperties: |
      <property>
        <name>fs.s3a.endpoint</name>
        <value>s3.eu-west-3.amazonaws.com</value>
      </property>
      <property>
        <name>fs.s3a.path.style.access</name>
        <value>false</value>
      </property>
      <property>
        <name>fs.s3a.block.size</name>
        <value>134217728</value>
      </property>
      <property>
        <name>fs.s3a.multipart.size</name>
        <value>67108864</value>
      </property>

  # Option 2: Google Cloud Storage
  # type: "gcp"
  # gcp:
  #   bucketName: "your-gcs-bucket"
  #   path: "/"
  #   authentication: "auto"

  # Option 3: Azure Storage
  # type: "azureStorage"
  # azureStorage:
  #   accountName: "your-storage-account"
  #   filesystem: "your-container"
  #   path: "/"
  #   authentication: "accessKey"
  #   credentials:
  #     accessKey: "YOUR_ACCESS_KEY"

# Service Account for cloud integration
serviceAccount:
  create: true
  name: dremio
  # For AWS EKS with IRSA:
  # annotations:
  #   eks.amazonaws.com/role-arn: "arn:aws:iam::ACCOUNT:role/dremio-s3-access"

# Monitoring and observability
monitoring:
  enabled: true
  serviceMonitor:
    enabled: true
    labels:
      prometheus: kube-prometheus-stack
  metrics:
    enabled: true
    port: 9010

# Security configurations
securityContext:
  runAsUser: 999
  runAsGroup: 999
  fsGroup: 999

podSecurityContext:
  runAsNonRoot: true
  runAsUser: 999
  fsGroup: 999

# Additional environment variables
extraEnv:
  - name: DREMIO_LOG_LEVEL
    value: INFO
  # Add AWS_REGION if using S3:
  # - name: AWS_REGION
  #   value: eu-west-3

# Zookeeper configuration (for high availability)
zookeeper:
  enabled: true
  replicaCount: 3
  persistence:
    enabled: true
    storageClass: "gp2"
    size: 10Gi