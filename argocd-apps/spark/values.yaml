# argocd-apps/spark/values.yaml
# Spark Operator Configuration

# Spark image to use
image:
  repository: gcr.io/spark-operator/spark-operator
  tag: v1beta2-1.3.8-3.1.1
  pullPolicy: IfNotPresent

# Spark job namespace (where Spark applications will run)
sparkJobNamespace: spark

# Enable webhook for validation
webhook:
  enable: true
  port: 8080

# Resource quotas and limits
resourceQuotaEnforcement:
  enable: false

# Controller settings
controllerThreads: 10
resyncInterval: 30

# Enable batch scheduler
batchScheduler:
  enable: false

# Metrics
metrics:
  enable: true
  port: 10254
  endpoint: /metrics
  prefix: ""

# Service Account
serviceAccounts:
  spark:
    create: true
    name: spark
  sparkoperator:
    create: true
    name: spark-operator

# RBAC
rbac:
  create: true

# Resources for the operator
resources:
  requests:
    cpu: 100m
    memory: 300Mi
  limits:
    cpu: 200m
    memory: 500Mi

# Node selector
nodeSelector: {}
  # node-group: system

# Monitoring - create ServiceMonitor for Prometheus
prometheus:
  metrics:
    enable: true
    port: 10254
    endpoint: /metrics

# Spark History Server will be deployed separately as a StatefulSet
# This section is for reference
historyServer:
  enabled: false  # We'll deploy it separately for more control